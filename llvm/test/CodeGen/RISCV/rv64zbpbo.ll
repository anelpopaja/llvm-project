; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv64 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64I
; RUN: llc -mtriple=riscv64 -mattr=+experimental-zbpbo -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64ZBPBO

define i64 @pack_i64(i64 %a, i64 %b) nounwind {
; RV64I-LABEL: pack_i64:
; RV64I:       # %bb.0:
; RV64I-NEXT:    slli a0, a0, 32
; RV64I-NEXT:    srli a0, a0, 32
; RV64I-NEXT:    slli a1, a1, 32
; RV64I-NEXT:    or a0, a1, a0
; RV64I-NEXT:    ret
;
; RV64ZBPBO-LABEL: pack_i64:
; RV64ZBPBO:       # %bb.0:
; RV64ZBPBO-NEXT:    pkbb32 a0, a0, a1
; RV64ZBPBO-NEXT:    ret
  %shl = and i64 %a, 4294967295
  %shl1 = shl i64 %b, 32
  %or = or i64 %shl1, %shl
  ret i64 %or
}

define i64 @packu_i64(i64 %a, i64 %b) nounwind {
; RV64I-LABEL: packu_i64:
; RV64I:       # %bb.0:
; RV64I-NEXT:    srli a0, a0, 32
; RV64I-NEXT:    srli a1, a1, 32
; RV64I-NEXT:    slli a1, a1, 32
; RV64I-NEXT:    or a0, a1, a0
; RV64I-NEXT:    ret
;
; RV64ZBPBO-LABEL: packu_i64:
; RV64ZBPBO:       # %bb.0:
; RV64ZBPBO-NEXT:    pktt32 a0, a0, a1
; RV64ZBPBO-NEXT:    ret
  %shr = lshr i64 %a, 32
  %shr1 = and i64 %b, -4294967296
  %or = or i64 %shr1, %shr
  ret i64 %or
}

define i64 @max_i64(i64 %a, i64 %b) nounwind {
; RV64I-LABEL: max_i64:
; RV64I:       # %bb.0:
; RV64I-NEXT:    blt a1, a0, .LBB2_2
; RV64I-NEXT:  # %bb.1:
; RV64I-NEXT:    mv a0, a1
; RV64I-NEXT:  .LBB2_2:
; RV64I-NEXT:    ret
;
; RV64ZBPBO-LABEL: max_i64:
; RV64ZBPBO:       # %bb.0:
; RV64ZBPBO-NEXT:    max a0, a0, a1
; RV64ZBPBO-NEXT:    ret
  %cmp = icmp sgt i64 %a, %b
  %cond = select i1 %cmp, i64 %a, i64 %b
  ret i64 %cond
}

define i64 @min_i64(i64 %a, i64 %b) nounwind {
; RV64I-LABEL: min_i64:
; RV64I:       # %bb.0:
; RV64I-NEXT:    blt a0, a1, .LBB3_2
; RV64I-NEXT:  # %bb.1:
; RV64I-NEXT:    mv a0, a1
; RV64I-NEXT:  .LBB3_2:
; RV64I-NEXT:    ret
;
; RV64ZBPBO-LABEL: min_i64:
; RV64ZBPBO:       # %bb.0:
; RV64ZBPBO-NEXT:    min a0, a0, a1
; RV64ZBPBO-NEXT:    ret
  %cmp = icmp slt i64 %a, %b
  %cond = select i1 %cmp, i64 %a, i64 %b
  ret i64 %cond
}

declare i16 @llvm.bswap.i16(i16)

define zeroext i16 @bswap_i16(i16 zeroext %a) nounwind {
; RV64I-LABEL: bswap_i16:
; RV64I:       # %bb.0:
; RV64I-NEXT:    srli a1, a0, 8
; RV64I-NEXT:    slli a0, a0, 8
; RV64I-NEXT:    or a0, a0, a1
; RV64I-NEXT:    slli a0, a0, 48
; RV64I-NEXT:    srli a0, a0, 48
; RV64I-NEXT:    ret
;
; RV64ZBPBO-LABEL: bswap_i16:
; RV64ZBPBO:       # %bb.0:
; RV64ZBPBO-NEXT:    rev8.h a0, a0
; RV64ZBPBO-NEXT:    ret
  %1 = tail call i16 @llvm.bswap.i16(i16 %a)
  ret i16 %1
}

define i64 @cmix_i64(i64 %a, i64 %b, i64 %c) nounwind {
; RV64I-LABEL: cmix_i64:
; RV64I:       # %bb.0:
; RV64I-NEXT:    and a0, a1, a0
; RV64I-NEXT:    not a1, a1
; RV64I-NEXT:    and a1, a1, a2
; RV64I-NEXT:    or a0, a1, a0
; RV64I-NEXT:    ret
;
; RV64ZBPBO-LABEL: cmix_i64:
; RV64ZBPBO:       # %bb.0:
; RV64ZBPBO-NEXT:    cmix a0, a1, a0, a2
; RV64ZBPBO-NEXT:    ret
  %and = and i64 %b, %a
  %neg = xor i64 %b, -1
  %and1 = and i64 %neg, %c
  %or = or i64 %and1, %and
  ret i64 %or
}
